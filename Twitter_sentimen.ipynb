{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "qXWagiDFsbO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = [\"Tweet_ID\", \"Entity\", \"Sentiment\", \"Tweet_Content\"]\n",
        "\n",
        "# Load dataset\n",
        "df_train = pd.read_csv(\"twitter_training.csv\", names=column_names, header=None)\n",
        "df_val = pd.read_csv(\"twitter_validation.csv\", names=column_names, header=None)\n",
        "\n",
        "# Cek isi dataset\n",
        "print(df_train.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8R6whC8scv2",
        "outputId": "f83cbacd-9d5a-4510-d250-2ea4c64cad88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Tweet_ID       Entity Sentiment  \\\n",
            "0      2401  Borderlands  Positive   \n",
            "1      2401  Borderlands  Positive   \n",
            "2      2401  Borderlands  Positive   \n",
            "3      2401  Borderlands  Positive   \n",
            "4      2401  Borderlands  Positive   \n",
            "\n",
            "                                       Tweet_Content  \n",
            "0  im getting on borderlands and i will murder yo...  \n",
            "1  I am coming to the borders and I will kill you...  \n",
            "2  im getting on borderlands and i will kill you ...  \n",
            "3  im coming on borderlands and i will murder you...  \n",
            "4  im getting on borderlands 2 and i will murder ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.columns)  # Cek semua nama kolom yang ada di dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQpD1IKkDsgb",
        "outputId": "4047790a-98fb-478d-e2c0-2b7a993e196f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Tweet_ID', 'Entity', 'Sentiment', 'Tweet_Content'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt_tab\")  # This line is added to download the necessary data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8byLzMeFY7C",
        "outputId": "f052c27e-80bf-4b10-e9f7-0ecc9753741c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()  # Konversi ke huruf kecil\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)  # Hapus URL\n",
        "    text = re.sub(r'\\d+', '', text)  # Hapus angka\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Hapus tanda baca\n",
        "    words = word_tokenize(text)  # Tokenisasi\n",
        "    words = [word for word in words if word not in stop_words]  # Hapus stopwords\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Terapkan ke dataset\n",
        "df_train[\"cleaned_tweet\"] = df_train[\"Tweet_Content\"].apply(clean_text)\n",
        "df_val[\"cleaned_tweet\"] = df_val[\"Tweet_Content\"].apply(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVWMr88Ys0DR",
        "outputId": "8d0477bd-92d6-4199-87c1-423df6a3153e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df_train[\"sentiment_encoded\"] = label_encoder.fit_transform(df_train[\"Sentiment\"])\n",
        "df_val[\"sentiment_encoded\"] = label_encoder.transform(df_val[\"Sentiment\"])\n",
        "\n",
        "# Cek hasil encoding\n",
        "print(label_encoder.classes_)  # Lihat urutan label yang dikonversi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE9uHn2pFhnx",
        "outputId": "0059eb43-3931-4570-9524-8d75768fb021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Irrelevant' 'Negative' 'Neutral' 'Positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit-transform pada training set, transform pada validation set\n",
        "X_train = tfidf_vectorizer.fit_transform(df_train[\"cleaned_tweet\"]).toarray()\n",
        "X_val = tfidf_vectorizer.transform(df_val[\"cleaned_tweet\"]).toarray()\n",
        "\n",
        "# Label\n",
        "y_train = df_train[\"sentiment_encoded\"]\n",
        "y_val = df_val[\"sentiment_encoded\"]\n"
      ],
      "metadata": {
        "id": "w6ov5cdEGFVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Inisialisasi model multi-class\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Evaluasi\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_pred, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JnyDzJ6GHwE",
        "outputId": "65bfc62f-c80c-4112-e96a-ce4e50538df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.802\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.81      0.72      0.76       172\n",
            "    Negative       0.77      0.86      0.81       266\n",
            "     Neutral       0.83      0.75      0.79       285\n",
            "    Positive       0.81      0.86      0.83       277\n",
            "\n",
            "    accuracy                           0.80      1000\n",
            "   macro avg       0.80      0.80      0.80      1000\n",
            "weighted avg       0.80      0.80      0.80      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    cleaned_text = clean_text(text)\n",
        "    vectorized_text = tfidf_vectorizer.transform([cleaned_text]).toarray()\n",
        "    prediction = model.predict(vectorized_text)\n",
        "    return label_encoder.inverse_transform(prediction)[0]  # Konversi kembali ke label aslinya\n",
        "\n",
        "new_tweet = \"I love playing Borderlands, it's amazing!\"\n",
        "print(predict_sentiment(new_tweet))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V86rN5T0JC2d",
        "outputId": "3f67977a-7784-4136-f0b9-8f1e66f9b536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    }
  ]
}